# Deep Learning Courses

## Even semester

### CSE Department

#### 1. **CS 419 M** : <u>Introduction to Machine Learning</u>
**Syllabus**
Basic classification/regression techniques such as Naive Bayes', decision trees, SVMs, boosting/bagging and linear/logistic regression, maximum likelihood estimates, regularization, basics of statistical learning theory, perceptron rule/multi-layer perceptrons, backpropagation, brief introduction to deep learning models, dimensionality reduction techniques like PCA and LDA, unsupervised learning: k-means clustering, gaussian mixture models, selected topics from natural/spoken language processing, computer vision, etc.

**Pre-requisites**
None

####  **CS 621** : <u>Artificial Intelligence</u>
**Syllabus**
Knowledge Representation: The First Order Predicate Logic, Production Systems, Semantic Nets, Frames and Scripts Formalisms. Resolution in Predicate Logic, Unification, Strategies for Resolution by Refutation. Knowledge Acquisition and learning: Learning from examples and analogy, Rote learning, Neural Learning, Integrated Approach. Planning and Robotics: STRIPS, ABSTRIPS, NOAH and MOLGEN planners, preliminary ideas of distributed and real time planning, Subsumption architecture based planning. Expert Systems: fundamental blocks, case studies in various domains, concept of shells, connectionist expert systems. Introduction to Natural Language Understanding: problems of ambiguity, ellipsis and polysemy, lexicalization and parsing, Transition and Augumented Transition networks, Natural Language Interfaces. Introdution to Computer Vision: Edge detection, Point Correspondence and Stereopsis, Surface directions. Basics of Neural Networks: Perceptrons, Feedforward nets Backpropagation algorithm, preliminary understanding of unsupervised learning.

**Pre-requisites**
None

#### **CS726** : <u>Advanced machine learning</u>
**Syllabus** 
This course will concentrate on modeling, generation, and prediction of multiple inter-dependent variables. The topics covered will span probabilistics graphical models (directed and undirected), inference methods like junction trees, belief propagation, and other approximate methods, sampling methods like MCMC, variational auto-encoders, GANs, neural architectures for sequence and graph-structured predictions. When appropriate the techniques will be linked to applications in translation, conversation modeling, speed recognition, graphics, and science.

**Pre-requisites**
A formal introductory ML course like CS 725 or CS 337 or CS 419 is required. Online ML courses do not qualify as pre-requisites. The course assumes basic knowledge of probability, statistics, and linear algebra. Chapters 2 and 3 of the [Deep-learning book](http://www.deeplearningbook.org/) are a good place to refresh the necessary required background. Also, the course assumes basic background in machine learning, for example as covered in Chapter 5 of the [Deep-learning book](http://www.deeplearningbook.org/) and deep learning, for example, as covered in Chapter 6 of the same book. Further, we will assume that students are familiar with CNNs, RNNs, and sequence to sequence learning with attention.

#### CS 748 : <u> Advances in Intelligent and Learning Agents</u>

**Syllabus**
Artificial intelligence is fast making inroads into various fields, and is indeed influencing our lives in a telling way. This course will accustom students to the state-of-the-art in designing and deploying intelligent and learning agents. The course will build upon the platform laid by CS 747 (Foundations of Intelligent and Learning Agents) to engage students in targeted research and system-building projects.

The course has three main objectives. First, it seeks to impart students the mindset that artificial intelligence and machine learning can substantially benefit real-world problems, and give them the confidence that they can drive this process. Second, the course seeks to develop the students' skills to abstract, analyse, design, implement, evaluate, and iterate while devising solutions. The third objective of the course is to train students to comprehend technical discourse and sharpen their communication skills.

The course is organised in the form of two parallel tracks:  **class discussions**  based on research papers, and a semester-long  **research project**. Students will be provided a reading assignment every week, and will be expected to turn in a response summarising their understanding and related observations. Individual responses will be shared with the class, and will guide the class discussion, which will be led by a group of 2-3 designated students. Topics covered in the reading assignments will include, among others, (1) philosophy of AI, (2) animal behaviour, (3) POMDPs, (4) evolutionary computation, (5) representation discovery, (6) crowdsourcing, (7) contextual bandits, (8) theoretical analysis of MDP planning and learning, (9) Monte Carlo tree search, (10) game-playing, and (11) robotics.

The research project presents an opportunity to students for applying their learning in creative and imaginative ways to understand, build, and analyse systems. Both theoretical and empirical investigations may be undertaken. Students may work alone or in teams. Each team will be guided individually through the phases of the research project, but will share its progress with the class at designated intervals.

**Pre-requisites**
CS 747 and consent of instructor

#### CS 753 : <u>Automatic Speech Recognition</u>
**Syllabus**
Introduction to the statistical approach for automatic speech recognition (ASR)  
* Weighted Finite State Transducers and their Application to ASR  
* Acoustic Signal Processing for ASR  
* Acoustic models: Hidden Markov Models, Gaussian Mixture Models, Baum-Welch Maximum Likelihood  
Estimation  
* Discriminative Training of Acoustic Models: Maximum Mutual Information, Minimum Word/Phone Error Criteria  
* Acoustic models continued: Neural network models (Deep feed-forward neural networks, convolutional neural networks and recurrent neural networks)  
* Pronunciation models: Pronunciation dictionaries, grapheme-to-phoneme models, feature-based models  
* N-gram language models: estimation, smoothing  
* ASR decoding problem: search algorithms, Viterbi estimation, finite-state transducer optimizations  
Programming assignments for a few of the above listed topics, along with a final research project, will be part of the curriculum.

**Pre-requisites**
This course is open to 3rd and 4th year B.Tech., M.Tech. and Ph.D. students, who have passed a formal course in ML (offered by either the CSE, EE or IEOR department).

#### CS 772 : Deep Learning for Natural Language Processing
**Syllabus** 
Background: History of Neural Nets; History of NLP; Basic Mathematical Machinery- Linear Algebra, Probability, Information Theory etc.; Basic Linguistic Machinery- Phonology, morphology, syntax, semantics Introducing Neural Computation: Perceptrons, Feedforward Neural Network and Backpropagation, Recurrent Neural Nets Difference between Classical Machine Learning and Deep Learning: Representation- Symbolic Representation, Distributed Representation, Compositionality; Parametric and non-parametric learning Word Embeddings: Word2Vec (CBOW and Skip Gram), Glove, FastText Application of Word Embedding to Shallow Parsing- Morphological Processing, Part of Speech Tagging and Chunking Sequence to Sequence (seq2seq) Transformation using Deep Learning: LSTMs and Variants, Attention, Transformers Deep Neural Net based Language Modeling: XLM, BERT, GPT2-3 etc; Subword Modeling; Transfer Learning and Multilingual Modeling Application of seq2seq in Machine Translation: supervised, semi supervised and unsupervised MT; encoder-decoder and attention in MT; Memory Networks in MT Deep Learning and Deep Parsing: Recursive Neural Nets; Neural Constituency Parsing; Neural Dependency Parsing Deep Learning and Deep Semantics: Word Embeddings and Word Sense Disambiguation; Semantic Role Labeling with Neural Nets Indispensability of DNN in Multimodal NLP; Advanced Problems like Sarcasm, Metaphor, Humour and Fake News Detection using multimodality and DNN Natural Language Generation; Extractive and Abstractive Summarizationwith Neural Nets- Explainability

**Pre-requisites**
N/A

#### CS 769 :  <u>Optimization in Machine Learning</u>
**Syllabus** 
N/A

**Pre-requisites**
N/A

### EE Department




<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE4MjI2ODc2MjYsMTgwMDMyODgxNl19
-->